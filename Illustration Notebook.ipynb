{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Neural Network Calibration for Predicting Implied Volatility and Log-Moneyness\n",
    "This Jupyter Notebook demonstrates the results of a Neural Network calibrated to predict Implied Volatility (IV) and Log-Moneyness (Log(F/K)). The primary goal is to validate the model’s consistency with the Black-Scholes framework, focusing on relationships between Greeks, Implied Volatility, Days to Expiry (DTE), and Log-Moneyness.\n",
    "\n",
    "The model was calibrated over 50 epochs using synthetically generated data, structured on an exhaustive grid with 100 points for each dimension (DTE, IV, Log(F/K)), resulting in a dataset size of 1,000,000 samples. This comprehensive approach ensures broad coverage of typical parameter ranges.\n",
    "\n",
    "To optimize performance:\n",
    "\n",
    "GPU-accelerated training was employed, leading to faster calibration times.\n",
    "Peak VRAM usage was capped at 1.6 GB, despite 16 GB being available, ensuring computational efficiency and scalability.\n",
    "The graphs below compare the predicted vs actual values for Log-Moneyness and IV, showcasing the accuracy of the calibration process. These results provide a foundation for verifying consistency across the model’s outputs and the theoretical expectations of the Black-Scholes framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating training data...\n",
      "Training the model...\n",
      "Epoch 1/100, Loss: 0.037526\n",
      "Epoch 2/100, Loss: 0.004154\n",
      "Epoch 3/100, Loss: 0.011520\n",
      "Epoch 4/100, Loss: 0.002537\n",
      "Epoch 5/100, Loss: 0.002289\n",
      "Epoch 6/100, Loss: 0.002127\n",
      "Epoch 7/100, Loss: 0.001897\n",
      "Epoch 8/100, Loss: 0.001825\n",
      "Epoch 9/100, Loss: 0.001781\n",
      "Epoch 10/100, Loss: 0.001710\n",
      "Epoch 11/100, Loss: 0.001676\n",
      "Epoch 12/100, Loss: 0.001645\n",
      "Epoch 13/100, Loss: 0.001604\n",
      "Epoch 14/100, Loss: 0.001577\n",
      "Epoch 15/100, Loss: 0.001562\n",
      "Epoch 16/100, Loss: 0.001531\n",
      "Epoch 17/100, Loss: 0.001521\n",
      "Epoch 18/100, Loss: 0.001484\n",
      "Epoch 19/100, Loss: 0.002264\n",
      "Epoch 20/100, Loss: 0.001487\n",
      "Epoch 21/100, Loss: 0.001484\n",
      "Epoch 22/100, Loss: 0.001462\n",
      "Epoch 23/100, Loss: 0.001547\n",
      "Epoch 24/100, Loss: 0.001420\n",
      "Epoch 25/100, Loss: 0.001420\n",
      "Epoch 26/100, Loss: 0.001398\n",
      "Epoch 27/100, Loss: 0.001562\n",
      "Epoch 28/100, Loss: 0.001376\n",
      "Epoch 29/100, Loss: 0.001378\n",
      "Epoch 30/100, Loss: 0.001364\n",
      "Epoch 31/100, Loss: 0.001357\n",
      "Epoch 32/100, Loss: 0.001359\n",
      "Epoch 33/100, Loss: 0.001343\n",
      "Epoch 34/100, Loss: 0.001339\n",
      "Epoch 35/100, Loss: 0.001326\n",
      "Epoch 36/100, Loss: 0.001319\n",
      "Epoch 37/100, Loss: 0.001448\n",
      "Epoch 38/100, Loss: 0.001319\n",
      "Epoch 39/100, Loss: 0.001316\n",
      "Epoch 40/100, Loss: 0.001321\n",
      "Epoch 41/100, Loss: 0.001310\n",
      "Epoch 42/100, Loss: 0.001306\n",
      "Epoch 43/100, Loss: 0.001293\n",
      "Epoch 44/100, Loss: 0.001299\n",
      "Epoch 45/100, Loss: 0.001315\n",
      "Epoch 46/100, Loss: 0.001297\n",
      "Epoch 47/100, Loss: 0.001287\n",
      "Epoch 48/100, Loss: 0.001288\n",
      "Epoch 49/100, Loss: 0.001417\n",
      "Epoch 50/100, Loss: 0.001287\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Suppress all warnings\u001b[39;00m\n\u001b[0;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mNeuralNetworkExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paula\\OneDrive\\Documents\\Experimental projects\\Reverse Black Scholes Neural Network GPU Learning\\NeuralNetworkExperiment.py:140\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m--> 140\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m    143\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model_dynamic.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\paula\\OneDrive\\Documents\\Experimental projects\\Reverse Black Scholes Neural Network GPU Learning\\NeuralNetworkExperiment.py:70\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, optimizer, loss_fn, device, epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[0;32m     69\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 70\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     73\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\paula\\OneDrive\\Documents\\Experimental projects\\Reverse Black Scholes Neural Network GPU Learning\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\paula\\OneDrive\\Documents\\Experimental projects\\Reverse Black Scholes Neural Network GPU Learning\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\paula\\OneDrive\\Documents\\Experimental projects\\Reverse Black Scholes Neural Network GPU Learning\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Calibration\n",
    "import NeuralNetworkExperiment\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "NeuralNetworkExperiment.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuralNetworkPrediction\n",
    "\n",
    "NeuralNetworkPrediction.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high deviations observed at the extremities might stem from distortions in the Black-Scholes model when dealing with extreme input values. As a general rule, the closer the predictions are to the diagonal, the better the calibration.\n",
    "\n",
    "An alternative way to validate the model is to fix specific values for Implied Volatility (IV) and Days to Expiry (DTE), then generate Greeks across a range of log-moneyness values. Using this generated data, the neural network should be able to reverse-engineer the log-moneyness range and recover the (constant) volatility.\n",
    "\n",
    "Below, we illustrate this alternative validation method. In essence, this approach is equivalent to plotting the Greeks across multiple log-moneyness values but applied in reverse—recovering log-moneyness and IV from the neural network's predictions.\n",
    "\n",
    "The implied volatility graph shows the ratio of Predicted IV to Real IV. Within the specified log-moneyness range and for the chosen IV, the predictions demonstrate high accuracy, with a deviation of approximately 40 basis points (bps). For example, if the true IV is 20%, the predicted IV lies within 20% ± 0.40%×20%, showcasing excellent precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AlternativeValidation\n",
    "\n",
    "AlternativeValidation.validate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
